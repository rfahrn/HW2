{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ahnki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ahnki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ahnki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ahnki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "custom_stopwords = ['says', 'said','one','new' ,'news']\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\" Clean text data by removing special characters and stopwords\"\"\"\n",
    "    if text.startswith(\"b'\") or text.startswith('b\"'):\n",
    "        text = text[2:-1]\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = bytes(text, 'utf-8').decode('unicode_escape', 'ignore')\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Keep only nouns and adjectives\n",
    "    words = [word for word, tag in pos_tags if tag in ['NN', 'JJ']]\n",
    "    #words = re.findall(r'\\w+', text) \n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# fill missing values and clean text\n",
    "for i in range(1, 26):\n",
    "    topic = f'Top{i}'\n",
    "    train[topic] = train[topic].fillna('').apply(clean_text)\n",
    "    test[topic] = test[topic].fillna('').apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>georgia russian war</td>\n",
       "      <td>musharraf</td>\n",
       "      <td>russia today column south ossetia footage youtube</td>\n",
       "      <td>russian capital south ossetia georgian artille...</td>\n",
       "      <td>afghan impunity official sick year old nothing</td>\n",
       "      <td>russian south ossetia whilst georgia russian</td>\n",
       "      <td>georgia ossetia russia side</td>\n",
       "      <td>enemy combatent nothing sham salim haman</td>\n",
       "      <td>...</td>\n",
       "      <td>georgia ossetia russia absorb georgia full sca...</td>\n",
       "      <td>alqaeda islamist backlash</td>\n",
       "      <td>condoleezza rice israeli strike iran israeli d...</td>\n",
       "      <td>busy day european union iran protest nuclear p...</td>\n",
       "      <td>georgia iraq russian georgia breakaway region ...</td>\n",
       "      <td>pentagon iran bad idea world report</td>\n",
       "      <td>caucasus crisis georgia ossetia</td>\n",
       "      <td>indian shoe manufactory series work</td>\n",
       "      <td>mental</td>\n",
       "      <td>help mexico kidnapping surge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>wont america nato iraq</td>\n",
       "      <td>bush georgian conflict</td>\n",
       "      <td>jewish georgian minister training russia</td>\n",
       "      <td>georgian army disarray gori shot</td>\n",
       "      <td>olympic ceremony</td>\n",
       "      <td>mossad fraudulent zealand iraq</td>\n",
       "      <td>russia israeli military sale</td>\n",
       "      <td>american citizen living sossetia georgian geno...</td>\n",
       "      <td>...</td>\n",
       "      <td>israel georgian aggression</td>\n",
       "      <td>tv russian georgian</td>\n",
       "      <td>montreal canada police boy saturday</td>\n",
       "      <td>china manufacturer</td>\n",
       "      <td>war south ossetia</td>\n",
       "      <td>israeli group state torture</td>\n",
       "      <td>russia united head peak oil</td>\n",
       "      <td>question georgia russia conflict</td>\n",
       "      <td>russia much war</td>\n",
       "      <td>come trading sex food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>adorable yearold opening</td>\n",
       "      <td>russia georgia operation</td>\n",
       "      <td>sexual harassment</td>\n",
       "      <td>alqaeda support iraq brutal crackdown unislamic</td>\n",
       "      <td>ceasefire georgia putin west</td>\n",
       "      <td>microsoft intel laptop</td>\n",
       "      <td>russogeorgian war balance power</td>\n",
       "      <td>im sense whole georgiarussia war vote</td>\n",
       "      <td>...</td>\n",
       "      <td>georgia georgia first place</td>\n",
       "      <td>russia response georgia right</td>\n",
       "      <td>gorbachev serious blunder interest caucasus re...</td>\n",
       "      <td>russia georgia nato cold war</td>\n",
       "      <td>adorable yearold country war evidence</td>\n",
       "      <td>war georgia israeli connection</td>\n",
       "      <td>point encouraging georgia south ossetia goddam...</td>\n",
       "      <td>christopher georgian invasion south ossetia ru...</td>\n",
       "      <td>mexico</td>\n",
       "      <td>bbc asiapacific extinction man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                      Top1                      Top2  \\\n",
       "0  2008-08-08      0       georgia russian war                 musharraf   \n",
       "1  2008-08-11      1    wont america nato iraq    bush georgian conflict   \n",
       "2  2008-08-12      0  adorable yearold opening  russia georgia operation   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  russia today column south ossetia footage youtube   \n",
       "1           jewish georgian minister training russia   \n",
       "2                                  sexual harassment   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  russian capital south ossetia georgian artille...   \n",
       "1                   georgian army disarray gori shot   \n",
       "2    alqaeda support iraq brutal crackdown unislamic   \n",
       "\n",
       "                                             Top5  \\\n",
       "0  afghan impunity official sick year old nothing   \n",
       "1                                olympic ceremony   \n",
       "2                    ceasefire georgia putin west   \n",
       "\n",
       "                                           Top6  \\\n",
       "0  russian south ossetia whilst georgia russian   \n",
       "1                mossad fraudulent zealand iraq   \n",
       "2                        microsoft intel laptop   \n",
       "\n",
       "                              Top7  \\\n",
       "0      georgia ossetia russia side   \n",
       "1     russia israeli military sale   \n",
       "2  russogeorgian war balance power   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0           enemy combatent nothing sham salim haman  ...   \n",
       "1  american citizen living sossetia georgian geno...  ...   \n",
       "2              im sense whole georgiarussia war vote  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  georgia ossetia russia absorb georgia full sca...   \n",
       "1                         israel georgian aggression   \n",
       "2                        georgia georgia first place   \n",
       "\n",
       "                           Top17  \\\n",
       "0      alqaeda islamist backlash   \n",
       "1            tv russian georgian   \n",
       "2  russia response georgia right   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  condoleezza rice israeli strike iran israeli d...   \n",
       "1                montreal canada police boy saturday   \n",
       "2  gorbachev serious blunder interest caucasus re...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  busy day european union iran protest nuclear p...   \n",
       "1                                 china manufacturer   \n",
       "2                       russia georgia nato cold war   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  georgia iraq russian georgia breakaway region ...   \n",
       "1                                  war south ossetia   \n",
       "2              adorable yearold country war evidence   \n",
       "\n",
       "                                 Top21  \\\n",
       "0  pentagon iran bad idea world report   \n",
       "1          israeli group state torture   \n",
       "2       war georgia israeli connection   \n",
       "\n",
       "                                               Top22  \\\n",
       "0                    caucasus crisis georgia ossetia   \n",
       "1                        russia united head peak oil   \n",
       "2  point encouraging georgia south ossetia goddam...   \n",
       "\n",
       "                                               Top23            Top24  \\\n",
       "0                indian shoe manufactory series work           mental   \n",
       "1                   question georgia russia conflict  russia much war   \n",
       "2  christopher georgian invasion south ossetia ru...           mexico   \n",
       "\n",
       "                            Top25  \n",
       "0    help mexico kidnapping surge  \n",
       "1           come trading sex food  \n",
       "2  bbc asiapacific extinction man  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>cancer result sheer bad luck unhealthy researc...</td>\n",
       "      <td>iran united islamic state ploy region reality ...</td>\n",
       "      <td>poll antimuslim</td>\n",
       "      <td>uk royal family prince andrew lawsuit underage...</td>\n",
       "      <td>bus destination rural northern sweden malm big...</td>\n",
       "      <td>pakistani boat india navy chase board vessel p...</td>\n",
       "      <td>sweden third mosque arson attack week</td>\n",
       "      <td>french year</td>\n",
       "      <td>...</td>\n",
       "      <td>ukrainian minister tv closure russian</td>\n",
       "      <td>palestinian president mahmoud abbas serious co...</td>\n",
       "      <td>israeli security center killed hamas</td>\n",
       "      <td>year year syria fouryear conflict</td>\n",
       "      <td>secret underground complex development wmd nuc...</td>\n",
       "      <td>web freedom major global issue</td>\n",
       "      <td>austrian journalist erich mchel presentation h...</td>\n",
       "      <td>ukraine kiev</td>\n",
       "      <td>china harvesting executed</td>\n",
       "      <td>plug russia last independent tv station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>high speed train trip time current</td>\n",
       "      <td>ancient egypt sunday symbolic burial site god ...</td>\n",
       "      <td>china n korean soldier world</td>\n",
       "      <td>scotland fossil fuelfree renewable energy ener...</td>\n",
       "      <td>prime minister shinzo abe monday remorse world...</td>\n",
       "      <td>sex centre prince andrew scandal teen</td>\n",
       "      <td>gay relative hamas founder deportation canada ...</td>\n",
       "      <td>number female drug iran</td>\n",
       "      <td>...</td>\n",
       "      <td>islamic state budget expected surplus islamic ...</td>\n",
       "      <td>iceland eu application lift capital</td>\n",
       "      <td>blackfield capital founder value ruble thing r...</td>\n",
       "      <td>rocket stage earth rural chinese village</td>\n",
       "      <td>dead aircraft bomb greek tanker libyan port</td>\n",
       "      <td>belgian murderer van den bleeken request belgi...</td>\n",
       "      <td>czech president ukrainian pm yatsenyuk prime m...</td>\n",
       "      <td>vietnamese search bahamian cargo ship sinking</td>\n",
       "      <td>france end ukraine</td>\n",
       "      <td>china rare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>oil barrel</td>\n",
       "      <td>toyota fuel cell car future</td>\n",
       "      <td>young indian couple police protection death</td>\n",
       "      <td>senior figure islamic force syria eastern prov...</td>\n",
       "      <td>fukushima rice radiation st time disaster</td>\n",
       "      <td>spanish guilty financial audit court</td>\n",
       "      <td>abdullah saudi throne</td>\n",
       "      <td>taliban commander linkedin</td>\n",
       "      <td>...</td>\n",
       "      <td>india pakistan spread km mile stretch border d...</td>\n",
       "      <td>turkey erdogan corruption authority</td>\n",
       "      <td>spacex falcon launch recovery next launch wind...</td>\n",
       "      <td>cnn gambia coup</td>\n",
       "      <td>islamic state official</td>\n",
       "      <td>libya country entry</td>\n",
       "      <td>judicial inquiry france monday country notorio...</td>\n",
       "      <td>video moment cameraman factory small town colo...</td>\n",
       "      <td>syria united republican senator john mccain fo...</td>\n",
       "      <td>india set iris telescope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        Date                                               Top1  \\\n",
       "0   0  2015-01-02  cancer result sheer bad luck unhealthy researc...   \n",
       "1   1  2015-01-05                 high speed train trip time current   \n",
       "2   2  2015-01-06                                         oil barrel   \n",
       "\n",
       "                                                Top2  \\\n",
       "0  iran united islamic state ploy region reality ...   \n",
       "1  ancient egypt sunday symbolic burial site god ...   \n",
       "2                        toyota fuel cell car future   \n",
       "\n",
       "                                          Top3  \\\n",
       "0                              poll antimuslim   \n",
       "1                 china n korean soldier world   \n",
       "2  young indian couple police protection death   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  uk royal family prince andrew lawsuit underage...   \n",
       "1  scotland fossil fuelfree renewable energy ener...   \n",
       "2  senior figure islamic force syria eastern prov...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  bus destination rural northern sweden malm big...   \n",
       "1  prime minister shinzo abe monday remorse world...   \n",
       "2          fukushima rice radiation st time disaster   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  pakistani boat india navy chase board vessel p...   \n",
       "1              sex centre prince andrew scandal teen   \n",
       "2               spanish guilty financial audit court   \n",
       "\n",
       "                                                Top7  \\\n",
       "0              sweden third mosque arson attack week   \n",
       "1  gay relative hamas founder deportation canada ...   \n",
       "2                              abdullah saudi throne   \n",
       "\n",
       "                         Top8  ...  \\\n",
       "0                 french year  ...   \n",
       "1     number female drug iran  ...   \n",
       "2  taliban commander linkedin  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0              ukrainian minister tv closure russian   \n",
       "1  islamic state budget expected surplus islamic ...   \n",
       "2  india pakistan spread km mile stretch border d...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  palestinian president mahmoud abbas serious co...   \n",
       "1                iceland eu application lift capital   \n",
       "2                turkey erdogan corruption authority   \n",
       "\n",
       "                                               Top18  \\\n",
       "0               israeli security center killed hamas   \n",
       "1  blackfield capital founder value ruble thing r...   \n",
       "2  spacex falcon launch recovery next launch wind...   \n",
       "\n",
       "                                      Top19  \\\n",
       "0         year year syria fouryear conflict   \n",
       "1  rocket stage earth rural chinese village   \n",
       "2                           cnn gambia coup   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  secret underground complex development wmd nuc...   \n",
       "1        dead aircraft bomb greek tanker libyan port   \n",
       "2                             islamic state official   \n",
       "\n",
       "                                               Top21  \\\n",
       "0                     web freedom major global issue   \n",
       "1  belgian murderer van den bleeken request belgi...   \n",
       "2                                libya country entry   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  austrian journalist erich mchel presentation h...   \n",
       "1  czech president ukrainian pm yatsenyuk prime m...   \n",
       "2  judicial inquiry france monday country notorio...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0                                       ukraine kiev   \n",
       "1      vietnamese search bahamian cargo ship sinking   \n",
       "2  video moment cameraman factory small town colo...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                          china harvesting executed   \n",
       "1                                 france end ukraine   \n",
       "2  syria united republican senator john mccain fo...   \n",
       "\n",
       "                                     Top25  \n",
       "0  plug russia last independent tv station  \n",
       "1                               china rare  \n",
       "2                 india set iris telescope  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Date.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add date features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_feature(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add date feature to dataframe 'date'\n",
    "add_date_feature(train)\n",
    "add_date_feature(test)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>georgia russian war</td>\n",
       "      <td>musharraf</td>\n",
       "      <td>russia today south ossetia footage youtube</td>\n",
       "      <td>russian capital south ossetia georgian artille...</td>\n",
       "      <td>afghan impunity official sick year old nothing</td>\n",
       "      <td>russian south ossetia whilst georgia russian</td>\n",
       "      <td>georgia ossetia russia side</td>\n",
       "      <td>enemy combatent nothing sham salim haman</td>\n",
       "      <td>...</td>\n",
       "      <td>georgia iraq russian georgia breakaway region ...</td>\n",
       "      <td>pentagon iran bad idea world report</td>\n",
       "      <td>caucasus crisis georgia ossetia</td>\n",
       "      <td>indian shoe manufactory series work</td>\n",
       "      <td>mental</td>\n",
       "      <td>help kidnapping surge</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>georgia russian war musharraf russia today sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>wont america nato iraq</td>\n",
       "      <td>bush georgian conflict</td>\n",
       "      <td>jewish georgian minister training russia</td>\n",
       "      <td>georgian army disarray gori shot</td>\n",
       "      <td>olympic ceremony</td>\n",
       "      <td>mossad fraudulent zealand iraq</td>\n",
       "      <td>russia israeli military sale</td>\n",
       "      <td>american citizen sossetia georgian genocide in...</td>\n",
       "      <td>...</td>\n",
       "      <td>war south ossetia</td>\n",
       "      <td>israeli group state torture</td>\n",
       "      <td>russia united head peak oil</td>\n",
       "      <td>question georgia russia conflict</td>\n",
       "      <td>much war</td>\n",
       "      <td>come trading sex food</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>wont america nato iraq bush georgian conflict ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>adorable yearold opening</td>\n",
       "      <td>russia georgia operation</td>\n",
       "      <td>sexual harassment</td>\n",
       "      <td>alqaeda support iraq brutal crackdown unislamic</td>\n",
       "      <td>ceasefire georgia putin west</td>\n",
       "      <td>microsoft intel laptop</td>\n",
       "      <td>russogeorgian war balance power</td>\n",
       "      <td>im sense whole georgiarussia war vote</td>\n",
       "      <td>...</td>\n",
       "      <td>adorable yearold country war evidence</td>\n",
       "      <td>war georgia israeli connection</td>\n",
       "      <td>point georgia south ossetia goddamnit bush</td>\n",
       "      <td>christopher georgian invasion south ossetia ru...</td>\n",
       "      <td>mexico</td>\n",
       "      <td>bbc asiapacific extinction man</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>adorable yearold opening russia georgia operat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                      Top1                      Top2  \\\n",
       "0 2008-08-08      0       georgia russian war                 musharraf   \n",
       "1 2008-08-11      1    wont america nato iraq    bush georgian conflict   \n",
       "2 2008-08-12      0  adorable yearold opening  russia georgia operation   \n",
       "\n",
       "                                         Top3  \\\n",
       "0  russia today south ossetia footage youtube   \n",
       "1    jewish georgian minister training russia   \n",
       "2                           sexual harassment   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  russian capital south ossetia georgian artille...   \n",
       "1                   georgian army disarray gori shot   \n",
       "2    alqaeda support iraq brutal crackdown unislamic   \n",
       "\n",
       "                                             Top5  \\\n",
       "0  afghan impunity official sick year old nothing   \n",
       "1                                olympic ceremony   \n",
       "2                    ceasefire georgia putin west   \n",
       "\n",
       "                                           Top6  \\\n",
       "0  russian south ossetia whilst georgia russian   \n",
       "1                mossad fraudulent zealand iraq   \n",
       "2                        microsoft intel laptop   \n",
       "\n",
       "                              Top7  \\\n",
       "0      georgia ossetia russia side   \n",
       "1     russia israeli military sale   \n",
       "2  russogeorgian war balance power   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0           enemy combatent nothing sham salim haman  ...   \n",
       "1  american citizen sossetia georgian genocide in...  ...   \n",
       "2              im sense whole georgiarussia war vote  ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  georgia iraq russian georgia breakaway region ...   \n",
       "1                                  war south ossetia   \n",
       "2              adorable yearold country war evidence   \n",
       "\n",
       "                                 Top21  \\\n",
       "0  pentagon iran bad idea world report   \n",
       "1          israeli group state torture   \n",
       "2       war georgia israeli connection   \n",
       "\n",
       "                                        Top22  \\\n",
       "0             caucasus crisis georgia ossetia   \n",
       "1                 russia united head peak oil   \n",
       "2  point georgia south ossetia goddamnit bush   \n",
       "\n",
       "                                               Top23     Top24  \\\n",
       "0                indian shoe manufactory series work    mental   \n",
       "1                   question georgia russia conflict  much war   \n",
       "2  christopher georgian invasion south ossetia ru...    mexico   \n",
       "\n",
       "                            Top25  Year Month Day  \\\n",
       "0           help kidnapping surge  2008     8   8   \n",
       "1           come trading sex food  2008     8  11   \n",
       "2  bbc asiapacific extinction man  2008     8  12   \n",
       "\n",
       "                                       combined_text  \n",
       "0  georgia russian war musharraf russia today sou...  \n",
       "1  wont america nato iraq bush georgian conflict ...  \n",
       "2  adorable yearold opening russia georgia operat...  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tf-idf to vectorize for combined top 25 topics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# combine all top 25 topics into one column\n",
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "\n",
    "for i in range(1, 26):\n",
    "    topic = f'Top{i}'\n",
    "    df_train[topic] = df_train[topic].fillna('').apply(clean_text)\n",
    "    df_test[topic] = df_test[topic].fillna('').apply(clean_text)\n",
    "\n",
    "df_train['combined_text'] = df_train.iloc[:, 2:27].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "df_test['combined_text'] = df_test.iloc[:, 2:27].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "df_train.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>cancer result sheer bad luck unhealthy researc...</td>\n",
       "      <td>iran islamic state ploy region reality united ...</td>\n",
       "      <td>poll antimuslim</td>\n",
       "      <td>uk royal family prince lawsuit underage sex</td>\n",
       "      <td>bus destination rural northern sweden malm big...</td>\n",
       "      <td>pakistani boat india navy chase board vessel p...</td>\n",
       "      <td>sweden third mosque arson attack week</td>\n",
       "      <td>french year</td>\n",
       "      <td>...</td>\n",
       "      <td>secret underground complex development wmd nuc...</td>\n",
       "      <td>web freedom major global issue</td>\n",
       "      <td>austrian journalist erich mchel presentation a...</td>\n",
       "      <td>ukraine kiev</td>\n",
       "      <td>china harvesting</td>\n",
       "      <td>plug russia last independent tv station</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cancer result sheer bad luck unhealthy researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>high speed trip time current</td>\n",
       "      <td>ancient egypt sunday symbolic burial site god ...</td>\n",
       "      <td>china n korean world</td>\n",
       "      <td>scotland renewable energy energy country power...</td>\n",
       "      <td>prime minister shinzo abe monday remorse world...</td>\n",
       "      <td>sex centre prince scandal teen</td>\n",
       "      <td>gay relative hamas founder deportation canada ...</td>\n",
       "      <td>number female drug iran</td>\n",
       "      <td>...</td>\n",
       "      <td>dead aircraft bomb greek tanker libyan port</td>\n",
       "      <td>belgian murderer van den bleeken request belgi...</td>\n",
       "      <td>czech president ukrainian pm yatsenyuk prime m...</td>\n",
       "      <td>vietnamese search bahamian cargo ship sinking</td>\n",
       "      <td>france end ukraine</td>\n",
       "      <td></td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>high speed trip time current ancient egypt sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>oil barrel</td>\n",
       "      <td>toyota fuel cell car future</td>\n",
       "      <td>young indian couple police protection death</td>\n",
       "      <td>senior figure islamic force syria eastern prov...</td>\n",
       "      <td>fukushima rice radiation st time disaster</td>\n",
       "      <td>spanish guilty financial audit court</td>\n",
       "      <td>abdullah saudi throne</td>\n",
       "      <td>taliban commander linkedin</td>\n",
       "      <td>...</td>\n",
       "      <td>islamic state official</td>\n",
       "      <td>libya country entry</td>\n",
       "      <td>judicial inquiry france monday country notorio...</td>\n",
       "      <td>video moment cameraman factory small town colo...</td>\n",
       "      <td>united republican senator john mccain former f...</td>\n",
       "      <td>india iris telescope</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>oil barrel toyota fuel cell car future young i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       Date                                               Top1  \\\n",
       "0   0 2015-01-02  cancer result sheer bad luck unhealthy researc...   \n",
       "1   1 2015-01-05                       high speed trip time current   \n",
       "2   2 2015-01-06                                         oil barrel   \n",
       "\n",
       "                                                Top2  \\\n",
       "0  iran islamic state ploy region reality united ...   \n",
       "1  ancient egypt sunday symbolic burial site god ...   \n",
       "2                        toyota fuel cell car future   \n",
       "\n",
       "                                          Top3  \\\n",
       "0                              poll antimuslim   \n",
       "1                         china n korean world   \n",
       "2  young indian couple police protection death   \n",
       "\n",
       "                                                Top4  \\\n",
       "0        uk royal family prince lawsuit underage sex   \n",
       "1  scotland renewable energy energy country power...   \n",
       "2  senior figure islamic force syria eastern prov...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  bus destination rural northern sweden malm big...   \n",
       "1  prime minister shinzo abe monday remorse world...   \n",
       "2          fukushima rice radiation st time disaster   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  pakistani boat india navy chase board vessel p...   \n",
       "1                     sex centre prince scandal teen   \n",
       "2               spanish guilty financial audit court   \n",
       "\n",
       "                                                Top7  \\\n",
       "0              sweden third mosque arson attack week   \n",
       "1  gay relative hamas founder deportation canada ...   \n",
       "2                              abdullah saudi throne   \n",
       "\n",
       "                         Top8  ...  \\\n",
       "0                 french year  ...   \n",
       "1     number female drug iran  ...   \n",
       "2  taliban commander linkedin  ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  secret underground complex development wmd nuc...   \n",
       "1        dead aircraft bomb greek tanker libyan port   \n",
       "2                             islamic state official   \n",
       "\n",
       "                                               Top21  \\\n",
       "0                     web freedom major global issue   \n",
       "1  belgian murderer van den bleeken request belgi...   \n",
       "2                                libya country entry   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  austrian journalist erich mchel presentation a...   \n",
       "1  czech president ukrainian pm yatsenyuk prime m...   \n",
       "2  judicial inquiry france monday country notorio...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0                                       ukraine kiev   \n",
       "1      vietnamese search bahamian cargo ship sinking   \n",
       "2  video moment cameraman factory small town colo...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                   china harvesting   \n",
       "1                                 france end ukraine   \n",
       "2  united republican senator john mccain former f...   \n",
       "\n",
       "                                     Top25  Year Month Day  \\\n",
       "0  plug russia last independent tv station  2015     1   2   \n",
       "1                                           2015     1   5   \n",
       "2                     india iris telescope  2015     1   6   \n",
       "\n",
       "                                       combined_text  \n",
       "0  cancer result sheer bad luck unhealthy researc...  \n",
       "1  high speed trip time current ancient egypt sun...  \n",
       "2  oil barrel toyota fuel cell car future young i...  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "1    981\n",
      "0    630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "label_counts = df_train['Label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "class CTFIDFVectorizer(TfidfTransformer):\n",
    "    \"\"\"Convert a collection of raw documents to a matrix of c-TF-IDF features (class based tf-idf) - it is not a transformer model, it is a vectorizer model (it does not learn anything) - it is a modification of the TfidfTransformer class (it inherits from it) \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CTFIDFVectorizer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X: sp.csr_matrix, n_samples: int):\n",
    "        \"\"\"learn idf vector (global term weights) \"\"\"\n",
    "        _, n_features = X.shape\n",
    "        df = np.squeeze(np.asarray(X.sum(axis=0)))\n",
    "        idf = np.log(n_samples / df)\n",
    "        self._idf_diag = sp.diags(idf, offsets=0,\n",
    "                                  shape=(n_features, n_features),\n",
    "                                  format='csr',\n",
    "                                  dtype=np.float64)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: sp.csr_matrix) -> sp.csr_matrix:\n",
    "        \"\"\"transform a count-based matrix to c-TF-IDF / class based tf-idf \"\"\"\n",
    "        X = X * self._idf_diag\n",
    "        X = normalize(X, axis=1, norm='l1', copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Month_Start</th>\n",
       "      <th>Month_End</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>georgia russian war</td>\n",
       "      <td>musharraf</td>\n",
       "      <td>russia today south ossetia footage youtube</td>\n",
       "      <td>russian capital south ossetia georgian artille...</td>\n",
       "      <td>afghan impunity official sick year old nothing</td>\n",
       "      <td>russian south ossetia whilst georgia russian</td>\n",
       "      <td>georgia ossetia russia side</td>\n",
       "      <td>enemy combatent nothing sham salim haman</td>\n",
       "      <td>...</td>\n",
       "      <td>help kidnapping surge</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>georgia russian war musharraf russia today sou...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>wont america nato iraq</td>\n",
       "      <td>bush georgian conflict</td>\n",
       "      <td>jewish georgian minister training russia</td>\n",
       "      <td>georgian army disarray gori shot</td>\n",
       "      <td>olympic ceremony</td>\n",
       "      <td>mossad fraudulent zealand iraq</td>\n",
       "      <td>russia israeli military sale</td>\n",
       "      <td>american citizen sossetia georgian genocide in...</td>\n",
       "      <td>...</td>\n",
       "      <td>come trading sex food</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>wont america nato iraq bush georgian conflict ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>adorable yearold opening</td>\n",
       "      <td>russia georgia operation</td>\n",
       "      <td>sexual harassment</td>\n",
       "      <td>alqaeda support iraq brutal crackdown unislamic</td>\n",
       "      <td>ceasefire georgia putin west</td>\n",
       "      <td>microsoft intel laptop</td>\n",
       "      <td>russogeorgian war balance power</td>\n",
       "      <td>im sense whole georgiarussia war vote</td>\n",
       "      <td>...</td>\n",
       "      <td>bbc asiapacific extinction man</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>adorable yearold opening russia georgia operat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                      Top1                      Top2  \\\n",
       "0 2008-08-08      0       georgia russian war                 musharraf   \n",
       "1 2008-08-11      1    wont america nato iraq    bush georgian conflict   \n",
       "2 2008-08-12      0  adorable yearold opening  russia georgia operation   \n",
       "\n",
       "                                         Top3  \\\n",
       "0  russia today south ossetia footage youtube   \n",
       "1    jewish georgian minister training russia   \n",
       "2                           sexual harassment   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  russian capital south ossetia georgian artille...   \n",
       "1                   georgian army disarray gori shot   \n",
       "2    alqaeda support iraq brutal crackdown unislamic   \n",
       "\n",
       "                                             Top5  \\\n",
       "0  afghan impunity official sick year old nothing   \n",
       "1                                olympic ceremony   \n",
       "2                    ceasefire georgia putin west   \n",
       "\n",
       "                                           Top6  \\\n",
       "0  russian south ossetia whilst georgia russian   \n",
       "1                mossad fraudulent zealand iraq   \n",
       "2                        microsoft intel laptop   \n",
       "\n",
       "                              Top7  \\\n",
       "0      georgia ossetia russia side   \n",
       "1     russia israeli military sale   \n",
       "2  russogeorgian war balance power   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0           enemy combatent nothing sham salim haman  ...   \n",
       "1  american citizen sossetia georgian genocide in...  ...   \n",
       "2              im sense whole georgiarussia war vote  ...   \n",
       "\n",
       "                            Top25  Year Month Day  \\\n",
       "0           help kidnapping surge  2008     8   8   \n",
       "1           come trading sex food  2008     8  11   \n",
       "2  bbc asiapacific extinction man  2008     8  12   \n",
       "\n",
       "                                       combined_text Day_of_Week Is_Weekend  \\\n",
       "0  georgia russian war musharraf russia today sou...           4          0   \n",
       "1  wont america nato iraq bush georgian conflict ...           0          0   \n",
       "2  adorable yearold opening russia georgia operat...           1          0   \n",
       "\n",
       "  Month_Start Month_End Quarter  \n",
       "0           0         0       3  \n",
       "1           0         0       3  \n",
       "2           0         0       3  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create count vectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000,stop_words=list(stop_words),ngram_range=(1,1), max_df=0.8, min_df=0.2)\n",
    "count_features_train = vectorizer.fit_transform(df_train['combined_text'])\n",
    "count_features_test = vectorizer.transform(df_test['combined_text'])\n",
    "\n",
    "# convert to dataframe \n",
    "count_df_train = pd.DataFrame(count_features_train.toarray(), columns=[f'count_{i}' for i in range(count_features_train.shape[1])])\n",
    "count_df_test = pd.DataFrame(count_features_test.toarray(), columns=[f'count_{i}' for i in range(count_features_test.shape[1])])\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "# create tf-idf vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words=list(stop_words), ngram_range=(1, 1))\n",
    "tfidf_features_train = tfidf.fit_transform(df_train['combined_text'])\n",
    "tfidf_features_test = tfidf.transform(df_test['combined_text'])\n",
    "\n",
    "tfidf_df_train = pd.DataFrame(tfidf_features_train.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_features_train.shape[1])])\n",
    "tfidf_df_test = pd.DataFrame(tfidf_features_test.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_features_test.shape[1])])\n",
    "tfidf_features_test = tfidf.transform(df_test['combined_text'])\n",
    "\n",
    "# features \n",
    "\n",
    "df_train['Day_of_Week'] = df_train['Date'].dt.dayofweek\n",
    "df_train['Is_Weekend'] = df_train['Day_of_Week'].apply(lambda x: 1 if x > 4 else 0)\n",
    "df_train['Month_Start'] = df_train['Date'].dt.is_month_start.astype(int)\n",
    "df_train['Month_End'] = df_train['Date'].dt.is_month_end.astype(int)\n",
    "df_train['Quarter'] = df_train['Date'].dt.quarter\n",
    "\n",
    "df_test['Day_of_Week'] = df_test['Date'].dt.dayofweek\n",
    "df_test['Is_Weekend'] = df_test['Day_of_Week'].apply(lambda x: 1 if x > 4 else 0)\n",
    "df_test['Month_Start'] = df_test['Date'].dt.is_month_start.astype(int)\n",
    "df_test['Month_End'] = df_test['Date'].dt.is_month_end.astype(int)\n",
    "df_test['Quarter'] = df_test['Date'].dt.quarter\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Initialize your CTFIDFVectorizer\n",
    "ctfidf_vectorizer = CTFIDFVectorizer()\n",
    "\n",
    "# Fit and transform using CTFIDFVectorizer\n",
    "n_samples_train = count_features_train.shape[0]\n",
    "n_samples_test = count_features_test.shape[0]\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>count_8</th>\n",
       "      <th>count_9</th>\n",
       "      <th>...</th>\n",
       "      <th>count_60</th>\n",
       "      <th>count_61</th>\n",
       "      <th>count_62</th>\n",
       "      <th>count_63</th>\n",
       "      <th>count_64</th>\n",
       "      <th>count_65</th>\n",
       "      <th>count_66</th>\n",
       "      <th>count_67</th>\n",
       "      <th>count_68</th>\n",
       "      <th>count_69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_0  count_1  count_2  count_3  count_4  count_5  count_6  count_7  \\\n",
       "0        1        0        0        0        0        0        0        1   \n",
       "1        1        1        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        1        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        1        0        1        0        1        0        0        0   \n",
       "\n",
       "   count_8  count_9  ...  count_60  count_61  count_62  count_63  count_64  \\\n",
       "0        0        0  ...         0         0         1         0         0   \n",
       "1        0        0  ...         0         0         0         0         0   \n",
       "2        0        0  ...         0         0         1         0         0   \n",
       "3        0        0  ...         0         0         0         0         0   \n",
       "4        0        0  ...         0         0         0         0         0   \n",
       "\n",
       "   count_65  count_66  count_67  count_68  count_69  \n",
       "0         1         5         0         2         1  \n",
       "1         0         3         0         1         0  \n",
       "2         1         7         0         1         0  \n",
       "3         0         0         0         0         1  \n",
       "4         1         3         0         2         0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# c-TF-IDF for training set\n",
    "X_ctfidf_train = ctfidf_vectorizer.fit(count_features_train, n_samples_train).transform(count_features_train)\n",
    "X_ctfidf_test = ctfidf_vectorizer.fit(count_features_test, n_samples_test).transform(count_features_test)\n",
    "# convert to dataframe \n",
    "X_ctfidf_train = pd.DataFrame(X_ctfidf_train.toarray(), columns=[f'count_{i}' for i in range(count_features_train.shape[1])])\n",
    "X_ctfidf_test = pd.DataFrame(X_ctfidf_test.toarray(), columns=[f'count_{i}' for i in range(count_features_test.shape[1])])\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_ctfidf_train, df_train[['Year', 'Month', 'Day','Quarter','Is_Weekend','Month_Start','Month_End','Day_of_Week']]], axis=1)\n",
    "X_test = pd.concat([X_ctfidf_test, df_test[['Year', 'Month', 'Day','Quarter','Is_Weekend','Month_Start','Month_End','Day_of_Week']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([count_df_train, df_train[['Year', 'Month', 'Day','Quarter','Is_Weekend','Month_Start','Month_End','Day_of_Week']]], axis=1)\n",
    "X_test = pd.concat([count_df_test, df_test[['Year', 'Month', 'Day','Quarter','Is_Weekend','Month_Start','Month_End','Day_of_Week']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use for tfidf \n",
    "X_train = pd.concat([tfidf_df_train, df_train[['Year', 'Month', 'Day','Quarter','Is_Weekend','Month_Start','Month_End','Day_of_Week']]], axis=1)\n",
    "X_test = pd.concat([tfidf_df_test, df_test[['Year', 'Month', 'Day','Quarter','Is_Weekend','Month_Start','Month_End','Day_of_Week']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>count_8</th>\n",
       "      <th>count_9</th>\n",
       "      <th>...</th>\n",
       "      <th>count_68</th>\n",
       "      <th>count_69</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Month_Start</th>\n",
       "      <th>Month_End</th>\n",
       "      <th>Day_of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080559</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055211</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    count_0   count_1   count_2  count_3  count_4   count_5  count_6  \\\n",
       "0  0.047485  0.000000  0.000000      0.0  0.00000  0.000000      0.0   \n",
       "1  0.080559  0.078873  0.000000      0.0  0.00000  0.000000      0.0   \n",
       "2  0.000000  0.000000  0.000000      0.0  0.00000  0.080285      0.0   \n",
       "3  0.000000  0.000000  0.000000      0.0  0.00000  0.000000      0.0   \n",
       "4  0.068084  0.000000  0.054991      0.0  0.04845  0.000000      0.0   \n",
       "\n",
       "    count_7  count_8  count_9  ...  count_68  count_69  Year  Month  Day  \\\n",
       "0  0.013492      0.0      0.0  ...  0.008747  0.025349  2008      8    8   \n",
       "1  0.000000      0.0      0.0  ...  0.007420  0.000000  2008      8   11   \n",
       "2  0.000000      0.0      0.0  ...  0.007009  0.000000  2008      8   12   \n",
       "3  0.000000      0.0      0.0  ...  0.000000  0.055211  2008      8   13   \n",
       "4  0.000000      0.0      0.0  ...  0.012542  0.000000  2008      8   14   \n",
       "\n",
       "   Quarter  Is_Weekend  Month_Start  Month_End  Day_of_Week  \n",
       "0        3           0            0          0            4  \n",
       "1        3           0            0          0            0  \n",
       "2        3           0            0          0            1  \n",
       "3        3           0            0          0            2  \n",
       "4        3           0            0          0            3  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>count_8</th>\n",
       "      <th>count_9</th>\n",
       "      <th>...</th>\n",
       "      <th>count_68</th>\n",
       "      <th>count_69</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Month_Start</th>\n",
       "      <th>Month_End</th>\n",
       "      <th>Day_of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080559</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055211</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    count_0   count_1   count_2  count_3  count_4   count_5  count_6  \\\n",
       "0  0.047485  0.000000  0.000000      0.0  0.00000  0.000000      0.0   \n",
       "1  0.080559  0.078873  0.000000      0.0  0.00000  0.000000      0.0   \n",
       "2  0.000000  0.000000  0.000000      0.0  0.00000  0.080285      0.0   \n",
       "3  0.000000  0.000000  0.000000      0.0  0.00000  0.000000      0.0   \n",
       "4  0.068084  0.000000  0.054991      0.0  0.04845  0.000000      0.0   \n",
       "\n",
       "    count_7  count_8  count_9  ...  count_68  count_69  Year  Month  Day  \\\n",
       "0  0.013492      0.0      0.0  ...  0.008747  0.025349  2008      8    8   \n",
       "1  0.000000      0.0      0.0  ...  0.007420  0.000000  2008      8   11   \n",
       "2  0.000000      0.0      0.0  ...  0.007009  0.000000  2008      8   12   \n",
       "3  0.000000      0.0      0.0  ...  0.000000  0.055211  2008      8   13   \n",
       "4  0.000000      0.0      0.0  ...  0.012542  0.000000  2008      8   14   \n",
       "\n",
       "   Quarter  Is_Weekend  Month_Start  Month_End  Day_of_Week  \n",
       "0        3           0            0          0            4  \n",
       "1        3           0            0          0            0  \n",
       "2        3           0            0          0            1  \n",
       "3        3           0            0          0            2  \n",
       "4        3           0            0          0            3  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, df_train['Label'].shape\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "X = X_train\n",
    "\n",
    "y = df_train['Label']\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "# count_cols = X_train.filter(regex='^count_').columns\n",
    "count_cols = X_train.filter(regex='^tfidf_').columns\n",
    "X_resampled[count_cols] = X_resampled[count_cols].astype(float) \n",
    "\n",
    "\n",
    "# Shuffle the dataset to ensure it's well mixed\n",
    "X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>count_3</th>\n",
       "      <th>count_4</th>\n",
       "      <th>count_5</th>\n",
       "      <th>count_6</th>\n",
       "      <th>count_7</th>\n",
       "      <th>count_8</th>\n",
       "      <th>count_9</th>\n",
       "      <th>...</th>\n",
       "      <th>count_68</th>\n",
       "      <th>count_69</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Month_Start</th>\n",
       "      <th>Month_End</th>\n",
       "      <th>Day_of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043252</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.102762</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count_0  count_1   count_2   count_3   count_4  count_5   count_6  \\\n",
       "294   0.056711      0.0  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "1674  0.000000      0.0  0.000000  0.043252  0.031492      0.0  0.027915   \n",
       "1379  0.000000      0.0  0.051827  0.000000  0.000000      0.0  0.000000   \n",
       "539   0.000000      0.0  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "407   0.000000      0.0  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "\n",
       "       count_7   count_8  count_9  ...  count_68  count_69  Year  Month  Day  \\\n",
       "294   0.000000  0.000000      0.0  ...  0.031340  0.000000  2009     10    8   \n",
       "1674  0.012574  0.000000      0.0  ...  0.008152  0.000000  2014      5    1   \n",
       "1379  0.000000  0.102762      0.0  ...  0.005910  0.102762  2014      1   31   \n",
       "539   0.018026  0.000000      0.0  ...  0.005843  0.000000  2010      9   29   \n",
       "407   0.067958  0.000000      0.0  ...  0.000000  0.000000  2010      3   23   \n",
       "\n",
       "      Quarter  Is_Weekend  Month_Start  Month_End  Day_of_Week  \n",
       "294         4           0            0          0            3  \n",
       "1674        2           0            1          0            3  \n",
       "1379        1           0            0          1            4  \n",
       "539         3           0            0          0            2  \n",
       "407         1           0            0          0            1  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# Parameters for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Parameters for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_features': ['log2', 'sqrt'],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['entropy'],\n",
    "    'class_weight': ['balanced'],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "\n",
    "# Parameters for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Pameters for XGBoost \n",
    "\n",
    "scale_pos_weight = len(df_train[df_train['Label'] == 0]) / len(df_train[df_train['Label'] == 1])\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.6, 1.0],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'scale_pos_weight': [scale_pos_weight]\n",
    "}\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, grid_params, X_train, y_train, X_val, y_val, X_test, model_name):\n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(model, grid_params , refit=True, verbose=3, cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Validation Prediction and Evaluation\n",
    "    y_val_pred = grid_search.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "    # Test Prediction\n",
    "    preds_test = grid_search.predict(X_test)\n",
    "    pd.DataFrame({'ID': np.arange(len(preds_test)), 'Label': preds_test}).to_csv(f'submission_{model_name}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "rf Accuracy: 0.6768447837150128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69       186\n",
      "           1       0.73      0.61      0.66       207\n",
      "\n",
      "    accuracy                           0.68       393\n",
      "   macro avg       0.68      0.68      0.68       393\n",
      "weighted avg       0.69      0.68      0.68       393\n",
      "\n",
      "[[140  46]\n",
      " [ 81 126]]\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "xgb Accuracy: 0.6692111959287532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       186\n",
      "           1       0.75      0.56      0.64       207\n",
      "\n",
      "    accuracy                           0.67       393\n",
      "   macro avg       0.68      0.68      0.67       393\n",
      "weighted avg       0.69      0.67      0.67       393\n",
      "\n",
      "[[147  39]\n",
      " [ 91 116]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# train_and_evaluate(SVC(max_iter=1000), param_grid_svm, X_train, y_train, X_val, y_val, X_test, 'svm')\n",
    "\n",
    "# Random Forest\n",
    "train_and_evaluate(RandomForestClassifier(), param_grid_rf, X_train, y_train, X_val, y_val, X_test, 'rf')\n",
    "\n",
    "# Logistic Regression\n",
    "# train_and_evaluate(LogisticRegression(max_iter=1000), param_grid_lr, X_train, y_train, X_val, y_val, X_test, 'lr')\n",
    "\n",
    "# XGBoost\n",
    "train_and_evaluate(xgb.XGBClassifier( ), param_grid_xgb, X_train, y_train, X_val, y_val, X_test, 'xgb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top25</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Month_Start</th>\n",
       "      <th>Month_End</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>georgia russian war</td>\n",
       "      <td>musharraf</td>\n",
       "      <td>russia today south ossetia footage youtube</td>\n",
       "      <td>russian capital south ossetia georgian artille...</td>\n",
       "      <td>afghan impunity official sick year old nothing</td>\n",
       "      <td>russian south ossetia whilst georgia russian</td>\n",
       "      <td>georgia ossetia russia side</td>\n",
       "      <td>enemy combatent nothing sham salim haman</td>\n",
       "      <td>...</td>\n",
       "      <td>help kidnapping surge</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>georgia russian war musharraf russia today sou...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>wont america nato iraq</td>\n",
       "      <td>bush georgian conflict</td>\n",
       "      <td>jewish georgian minister training russia</td>\n",
       "      <td>georgian army disarray gori shot</td>\n",
       "      <td>olympic ceremony</td>\n",
       "      <td>mossad fraudulent zealand iraq</td>\n",
       "      <td>russia israeli military sale</td>\n",
       "      <td>american citizen sossetia georgian genocide in...</td>\n",
       "      <td>...</td>\n",
       "      <td>come trading sex food</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>wont america nato iraq bush georgian conflict ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>adorable yearold opening</td>\n",
       "      <td>russia georgia operation</td>\n",
       "      <td>sexual harassment</td>\n",
       "      <td>alqaeda support iraq brutal crackdown unislamic</td>\n",
       "      <td>ceasefire georgia putin west</td>\n",
       "      <td>microsoft intel laptop</td>\n",
       "      <td>russogeorgian war balance power</td>\n",
       "      <td>im sense whole georgiarussia war vote</td>\n",
       "      <td>...</td>\n",
       "      <td>bbc asiapacific extinction man</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>adorable yearold opening russia georgia operat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>israel iran report</td>\n",
       "      <td>president capital come</td>\n",
       "      <td>israel cameraman</td>\n",
       "      <td>policy tough pointless former civil servant unit</td>\n",
       "      <td>body year old trunk ransom victim mexico head ...</td>\n",
       "      <td>prefab</td>\n",
       "      <td>bush operation</td>\n",
       "      <td>russian georgian</td>\n",
       "      <td>...</td>\n",
       "      <td>nobel laureate aleksander solzhenitsyn russia</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>israel iran report president capital come isra...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>war south osetia russian soldier</td>\n",
       "      <td>swedish wrestler ara abrahamian medal olympic ...</td>\n",
       "      <td>russia death toll south ossetia</td>\n",
       "      <td>missile pakistan cia</td>\n",
       "      <td>rushdie condemns random novel fear muslim reta...</td>\n",
       "      <td>poland defense deal interesting timing</td>\n",
       "      <td>tblisi bet</td>\n",
       "      <td>...</td>\n",
       "      <td>peace assurance</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>war south osetia russian soldier swedish wres...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Label                      Top1  \\\n",
       "0 2008-08-08      0       georgia russian war   \n",
       "1 2008-08-11      1    wont america nato iraq   \n",
       "2 2008-08-12      0  adorable yearold opening   \n",
       "3 2008-08-13      0        israel iran report   \n",
       "4 2008-08-14      1                             \n",
       "\n",
       "                               Top2  \\\n",
       "0                         musharraf   \n",
       "1            bush georgian conflict   \n",
       "2          russia georgia operation   \n",
       "3            president capital come   \n",
       "4  war south osetia russian soldier   \n",
       "\n",
       "                                                Top3  \\\n",
       "0         russia today south ossetia footage youtube   \n",
       "1           jewish georgian minister training russia   \n",
       "2                                  sexual harassment   \n",
       "3                                   israel cameraman   \n",
       "4  swedish wrestler ara abrahamian medal olympic ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  russian capital south ossetia georgian artille...   \n",
       "1                   georgian army disarray gori shot   \n",
       "2    alqaeda support iraq brutal crackdown unislamic   \n",
       "3   policy tough pointless former civil servant unit   \n",
       "4                    russia death toll south ossetia   \n",
       "\n",
       "                                                Top5  \\\n",
       "0     afghan impunity official sick year old nothing   \n",
       "1                                   olympic ceremony   \n",
       "2                       ceasefire georgia putin west   \n",
       "3  body year old trunk ransom victim mexico head ...   \n",
       "4                               missile pakistan cia   \n",
       "\n",
       "                                                Top6  \\\n",
       "0       russian south ossetia whilst georgia russian   \n",
       "1                     mossad fraudulent zealand iraq   \n",
       "2                             microsoft intel laptop   \n",
       "3                                             prefab   \n",
       "4  rushdie condemns random novel fear muslim reta...   \n",
       "\n",
       "                                     Top7  \\\n",
       "0             georgia ossetia russia side   \n",
       "1            russia israeli military sale   \n",
       "2         russogeorgian war balance power   \n",
       "3                          bush operation   \n",
       "4  poland defense deal interesting timing   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0           enemy combatent nothing sham salim haman  ...   \n",
       "1  american citizen sossetia georgian genocide in...  ...   \n",
       "2              im sense whole georgiarussia war vote  ...   \n",
       "3                                   russian georgian  ...   \n",
       "4                                         tblisi bet  ...   \n",
       "\n",
       "                                           Top25  Year Month Day  \\\n",
       "0                          help kidnapping surge  2008     8   8   \n",
       "1                          come trading sex food  2008     8  11   \n",
       "2                 bbc asiapacific extinction man  2008     8  12   \n",
       "3  nobel laureate aleksander solzhenitsyn russia  2008     8  13   \n",
       "4                                peace assurance  2008     8  14   \n",
       "\n",
       "                                       combined_text Day_of_Week Is_Weekend  \\\n",
       "0  georgia russian war musharraf russia today sou...           4          0   \n",
       "1  wont america nato iraq bush georgian conflict ...           0          0   \n",
       "2  adorable yearold opening russia georgia operat...           1          0   \n",
       "3  israel iran report president capital come isra...           2          0   \n",
       "4   war south osetia russian soldier swedish wres...           3          0   \n",
       "\n",
       "  Month_Start Month_End Quarter  \n",
       "0           0         0       3  \n",
       "1           0         0       3  \n",
       "2           0         0       3  \n",
       "3           0         0       3  \n",
       "4           0         0       3  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0\n",
      " 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0\n",
      " 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1\n",
      " 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1\n",
      " 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Final Accuracy on Feature-wise Validation Set: 0.5541795665634675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing helpers\n",
    "text_imputer = SimpleImputer(strategy='constant', fill_value='') \n",
    "num_imputer = SimpleImputer(strategy='mean') \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Initialize variables\n",
    "models = {}\n",
    "text_columns = ['Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15', 'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23', 'Top24', 'Top25']  # Textual features\n",
    "probabilities = []\n",
    "individual_models = {}\n",
    "num_columns = ['Year', 'Month', 'Day', 'Quarter', 'Is_Weekend', 'Month_Start', 'Month_End', 'Day_of_Week']  \n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train.drop(['Date','Label'], axis=1), df_train['Label'], test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "# Train models for each feature\n",
    "for col in df_train.columns:\n",
    "\n",
    "    if col in text_columns:\n",
    "        # Impute missing values for text columns\n",
    "        X_train_feature = text_imputer.fit_transform(X_train[[col]])\n",
    "        X_val_feature = text_imputer.transform(X_val[[col]])\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, stop_words=list(stop_words), ngram_range=(1, 1))\n",
    "        X_train_transformed = vectorizer.fit_transform(X_train_feature.ravel())\n",
    "        X_val_transformed = vectorizer.transform(X_val_feature.ravel())\n",
    "    elif col in num_columns:\n",
    "        # Convert to numeric, handle missing values, and scale for numerical columns\n",
    "        X_train_feature = pd.to_numeric(X_train[col], errors='coerce').values.reshape(-1, 1)\n",
    "        X_val_feature = pd.to_numeric(X_val[col], errors='coerce').values.reshape(-1, 1)\n",
    "        X_train_transformed = num_imputer.fit_transform(X_train_feature)\n",
    "        X_val_transformed = num_imputer.transform(X_val_feature)\n",
    "        X_train_transformed = scaler.fit_transform(X_train_transformed)\n",
    "        X_val_transformed = scaler.transform(X_val_transformed)\n",
    "    else:\n",
    "        continue  # Skip non-numeric, non-text columns\n",
    "\n",
    "    # Train the model\n",
    "    #model = LogisticRegression(max_iter=1000, C=1, penalty='l2', solver='lbfgs', random_state=42, n_jobs=-1)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=8, max_features='log2', criterion='entropy',class_weight='balanced')\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    models[col] = (model, vectorizer if col in text_columns else None)\n",
    "\n",
    "    # Store the probabilities for positive class\n",
    "    probabilities.append(model.predict_proba(X_val_transformed)[:, 1])\n",
    "\n",
    "\n",
    "# Average the probabilities\n",
    "average_prob = np.mean(probabilities, axis=0)\n",
    "\n",
    "# Convert average probabilities to binary predictions\n",
    "final_predictions = (average_prob > 0.5).astype(int)\n",
    "print(final_predictions)\n",
    "# Evaluate the final predictions\n",
    "final_accuracy = accuracy_score(y_val, final_predictions)\n",
    "print(f\"Final Accuracy on Feature-wise Validation Set: {final_accuracy}\") # 0.6346749226006192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5386996904024768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stacked_predictions_train = pd.DataFrame()\n",
    "stacked_predictions_test = pd.DataFrame()\n",
    "top_columns = ['Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15', 'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23', 'Top24', 'Top25']  # Textual features\n",
    "scale_pos_weight = len(df_train[df_train['Label'] == 0]) / len(df_train[df_train['Label'] == 1])\n",
    "\n",
    "# Define your base learners\n",
    "base_learners = [\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, colsample_bytree=0.7, subsample=1.0, gamma=0.5, booster='gbtree', scale_pos_weight=scale_pos_weight, n_jobs=-1, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', max_depth=8, max_features='log2', criterion='entropy', n_jobs=-1))\n",
    "]\n",
    "\n",
    "param_grid_meta = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'class_weight': ['balanced']\n",
    "\n",
    "}\n",
    "meta_learner = GridSearchCV(LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1), \n",
    "                                param_grid_meta, \n",
    "                                cv=5, \n",
    "                                scoring='accuracy', \n",
    "                                n_jobs=-1)\n",
    "\n",
    "\n",
    "for column in top_columns:\n",
    "    df_train[column] = df_train[column].fillna('').apply(clean_text)\n",
    "    X = df_train[column]\n",
    "    y = df_train['Label']\n",
    "\n",
    "    # Text Vectorization\n",
    "    vectorizer = TfidfVectorizer( max_features=5000, stop_words=list(stop_words), ngram_range=(1, 1))\n",
    "    X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # Stacking Classifier\n",
    "    stack_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "    stack_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Collect predictions for train and test set\n",
    "    stacked_predictions_train[column] = stack_clf.predict(X_train)\n",
    "    stacked_predictions_test[column] = stack_clf.predict(X_test)\n",
    "\n",
    "# Train meta-learner\n",
    "meta_learner.fit(stacked_predictions_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "final_predictions = meta_learner.predict(stacked_predictions_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Define hyperparameters for GridSearchCV for each base learner\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    # Add more parameters as needed\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    # Add more parameters as needed\n",
    "}\n",
    "\n",
    "# Function to train and return a model with GridSearchCV\n",
    "def train_model(X, y, model, param_grid):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Train and collect predictions\n",
    "for column in top_columns:\n",
    "    X = df_train[column]\n",
    "    y = df_train['Label']\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, stop_words=stop_words, ngram_range=(1, 1))\n",
    "    X_vectorized = vectorizer.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    best_rf = train_model(X_train, y_train, RandomForestClassifier(), param_grid_rf)\n",
    "    best_xgb = train_model(X_train, y_train, xgb.XGBClassifier(), param_grid_xgb)\n",
    "\n",
    "    stacked_predictions_train[column] = best_rf.predict(X_train) + best_xgb.predict(X_train)\n",
    "    stacked_predictions_test[column] = best_rf.predict(X_test) + best_xgb.predict(X_test)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1,\n",
       "                                          random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [100, 500, 1000], &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1,\n",
       "                                          random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [100, 500, 1000], &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced', n_jobs=-1,\n",
       "                                          random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced'],\n",
       "                         'max_iter': [100, 500, 1000], 'penalty': ['l2'],\n",
       "                         'solver': ['lbfgs']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train meta-learner\n",
    "meta_learner.fit(stacked_predictions_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5386996904024768\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "final_predictions = meta_learner.predict(stacked_predictions_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
