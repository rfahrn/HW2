{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2f8714-a25d-4393-95df-5a6f896b346e",
   "metadata": {},
   "source": [
    "# Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a3894-2de0-4cab-9fa5-3bb8d2793026",
   "metadata": {},
   "source": [
    "# Task Overview\n",
    "You are given a dataset of top news (of a day) and want to predict the movement (1 for up and 0 for down) of the market value.\n",
    "\n",
    "Download the data from [competition page](https://www.kaggle.com/t/664260fab9b04f699426b48a29ff7d05). This is also where you will upload your submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d396cc-65e7-48a9-92d9-1a231e244d8d",
   "metadata": {},
   "source": [
    "You need to improve the accuracy of the model as much as you can.\n",
    "\n",
    "## Rules:\n",
    "1. Do not use any external data **NOR** models pre-trained on other datasets\n",
    "2. Use the test set **ONLY** to get predictions for your model. For example, do not use it to compute statistics or features (e.g. learning preprocessing).\n",
    "3. Do not use deep learning models for a fair competition\n",
    "4. Don't cheat :)\n",
    "\n",
    "## Hints\n",
    "Here are several techniques that you can use:\n",
    "\n",
    "1. **Tune your hyper-parameters** Try `GridSerachCV` function from `sklearn.model_selection` to find the best set of hyperparameters.\n",
    "2. **Feature engineering** Play with the representation of the textual data. We only tried one, but there are more (e.g. TF-IDF Vectorizer is another powerful method to transform text to a vector, taking into account the rareness of the words across the texts). Also do not hesitate to play with the arguments of the *Vectorizers*. \n",
    "3. **Change your model** You are not restricted to train `LogisticRegression` only. You can use whatever algorithm you're already familiar with. Moreover, you can use the algorithms that you get to know during these 3 weeks of solving this assignment. E.g. give *RandomForests* a try!\n",
    "4. **Use date** You can also use the date as extra features, think how you can use it and look for some patterns!\n",
    "5. **Combine multiple models** You can train multiple models and use their individual predictions to produce a final, improved prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342cac2c-8ecf-4d46-a38b-97c93dfbac31",
   "metadata": {},
   "source": [
    "## Scoring rules [16 points + 20 bonus points]\n",
    "You have until **22.11.2023** to submit your tuned solutions.  \n",
    "**You also need to submit the code for your best solution before the deadline.**\n",
    "\n",
    "### **Part of the Assignment grade: [16 points]**\n",
    "You need to beat two thresholds in order to get a full set of points for the assignment:\n",
    "\n",
    "- You get **4 points** if you get at least 55% on the public board (`Super Easy Baseline`).\n",
    "\n",
    "- You get another **12 points** if you beat the **easy baseline** - 58%. (We also added two hard baselines just for a point of reference)\n",
    "\n",
    "### **Bonus points [up to 20 points]**\n",
    "- **Top-5** on the final leaderboard get **20 bonus points**\n",
    "\n",
    "- **Top-10** on the final leaderboard get **15 bonus points**\n",
    "\n",
    "- **Top-15** on the final leaderboard get **10 bonus points**\n",
    "\n",
    "- **Top-25** on the final leaderboard get **5 bonus points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25c666-a005-4485-9e72-59cd7cb4ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3) # look at the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3) # and the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naively concatenating all the news\n",
    "X_train = [' '.join(str(x) for x in train.iloc[row,2:27]) for row in range(len(train.index))]\n",
    "X_test = [' '.join(str(x) for x in test.iloc[row,2:27]) for row in range(len(test.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4c551",
   "metadata": {},
   "source": [
    "creating a local validation set (since we don't know the test labels and we have limited (per day) submissions to kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c76531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, train.Label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8fb48",
   "metadata": {},
   "source": [
    "One needs to transform the data to the format that can be used with the known classifiers.\n",
    "\n",
    "We need to represent each text as a classifier-friendly representation, for example: bag of words.\n",
    "\n",
    "Using *CountVectorizer* from *sklearn.feature_extraction.text* we can transform the *news* to a data matrix *X* of shape [num_days, vocabulary_size], where each row represents a single text and each column indicates the number of occurences of a specific word across the dataset.\n",
    "Notice that the Vectorizer has a lot of useful arguments. These could potentially influence the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a simple 1-gram encoder to encode texts\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec768c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple logistic regression and using it on transformed test cases\n",
    "model = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "preds = model.predict(vectorizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b9877",
   "metadata": {},
   "source": [
    "just to have a sense about our simple classifier, we will evaluate it on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ed0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((model.predict(X_val) == y_val).mean() * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f59d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a submission file for kaggle\n",
    "pd.DataFrame({'ID': np.arange(len(preds)), 'Label': preds}).to_csv('submission_1gram.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
